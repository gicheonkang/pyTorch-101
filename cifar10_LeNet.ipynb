{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "#hyper parameters\n",
    "input_size = 1024\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "momentum = 0.9\n",
    "num_class = 10\n",
    "num_epoch = 10\n",
    "\n",
    "# cifar10 dataset\n",
    "train_dataset = dsets.CIFAR10(root='./data', \n",
    "                              train=True,\n",
    "                              transform=transforms.ToTensor(),\n",
    "                              download=True)\n",
    "\n",
    "test_dataset = dsets.CIFAR10(root='./data',\n",
    "                            train=True,\n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CIFAR10, self).__init__()\n",
    "        # input channel, output channel, kernel_size, \n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_class)\n",
    "     \n",
    "    def forward(self, x):\n",
    "        # convolution step\n",
    "        l1 = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        l2 = F.max_pool2d(F.relu(self.conv2(l1)), 2)\n",
    "        \n",
    "        # flatten & fully connected layer\n",
    "        l2 = l2.view(-1, 16 * 5 * 5)\n",
    "        fully_contd1 = F.relu(self.fc1(l2))\n",
    "        fully_contd2 = F.relu(self.fc2(fully_contd1))\n",
    "        out = self.fc3(fully_contd2)\n",
    "        return out\n",
    "    \n",
    "    '''\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "    '''\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CF10 = CIFAR10()\n",
    "CF10.cuda(0)\n",
    "print (CF10)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(CF10.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: [1/10], step: [100/500], Loss: 1.9530\n",
      "epoch: [1/10], step: [200/500], Loss: 1.9035\n",
      "epoch: [1/10], step: [300/500], Loss: 1.6055\n",
      "epoch: [1/10], step: [400/500], Loss: 1.6775\n",
      "epoch: [1/10], step: [500/500], Loss: 1.5833\n",
      "epoch: [2/10], step: [100/500], Loss: 1.4339\n",
      "epoch: [2/10], step: [200/500], Loss: 1.6821\n",
      "epoch: [2/10], step: [300/500], Loss: 1.5873\n",
      "epoch: [2/10], step: [400/500], Loss: 1.4489\n",
      "epoch: [2/10], step: [500/500], Loss: 1.4384\n",
      "epoch: [3/10], step: [100/500], Loss: 1.4674\n",
      "epoch: [3/10], step: [200/500], Loss: 1.4580\n",
      "epoch: [3/10], step: [300/500], Loss: 1.3291\n",
      "epoch: [3/10], step: [400/500], Loss: 1.3230\n",
      "epoch: [3/10], step: [500/500], Loss: 1.2284\n",
      "epoch: [4/10], step: [100/500], Loss: 1.3777\n",
      "epoch: [4/10], step: [200/500], Loss: 1.2729\n",
      "epoch: [4/10], step: [300/500], Loss: 1.1461\n",
      "epoch: [4/10], step: [400/500], Loss: 1.3385\n",
      "epoch: [4/10], step: [500/500], Loss: 1.5855\n",
      "epoch: [5/10], step: [100/500], Loss: 1.1909\n",
      "epoch: [5/10], step: [200/500], Loss: 1.2089\n",
      "epoch: [5/10], step: [300/500], Loss: 1.1911\n",
      "epoch: [5/10], step: [400/500], Loss: 1.1780\n",
      "epoch: [5/10], step: [500/500], Loss: 1.0822\n",
      "epoch: [6/10], step: [100/500], Loss: 1.2436\n",
      "epoch: [6/10], step: [200/500], Loss: 1.3494\n",
      "epoch: [6/10], step: [300/500], Loss: 1.2945\n",
      "epoch: [6/10], step: [400/500], Loss: 1.2260\n",
      "epoch: [6/10], step: [500/500], Loss: 1.1971\n",
      "epoch: [7/10], step: [100/500], Loss: 1.0541\n",
      "epoch: [7/10], step: [200/500], Loss: 1.0402\n",
      "epoch: [7/10], step: [300/500], Loss: 1.2530\n",
      "epoch: [7/10], step: [400/500], Loss: 1.0395\n",
      "epoch: [7/10], step: [500/500], Loss: 1.1837\n",
      "epoch: [8/10], step: [100/500], Loss: 1.0894\n",
      "epoch: [8/10], step: [200/500], Loss: 1.0440\n",
      "epoch: [8/10], step: [300/500], Loss: 1.1329\n",
      "epoch: [8/10], step: [400/500], Loss: 1.0902\n",
      "epoch: [8/10], step: [500/500], Loss: 1.1128\n",
      "epoch: [9/10], step: [100/500], Loss: 1.0003\n"
     ]
    }
   ],
   "source": [
    "# training step\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    for i, (image, label) in enumerate(train_loader):\n",
    "        images = Variable(image.cuda()) #.view(-1, 3, 32, 32)\n",
    "        labels = Variable(label.cuda())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = CF10(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if(i+1) % 100 == 0:\n",
    "            print('epoch: [%d/%d], step: [%d/%d], Loss: %.4f' % (epoch+1, num_epoch, i+1, len(train_dataset)//batch_size, loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of the model : 29 %\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "for image, label in test_loader:\n",
    "    images = Variable(image.cuda())\n",
    "    #label = Variable(label.cuda())\n",
    "    _, predicted = torch.max(CF10(images).data, 1)\n",
    "    total += label.size(0)\n",
    "    correct += (predicted.cpu() == label).sum()\n",
    "print('accuracy of the model : %d %%' % (100*correct/total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:venv]",
   "language": "python",
   "name": "conda-env-venv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
